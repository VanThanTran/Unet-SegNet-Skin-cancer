{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary gdown\n#!pip install albumentations==0.4.6","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:38:43.300627Z","iopub.execute_input":"2022-01-26T10:38:43.301010Z","iopub.status.idle":"2022-01-26T10:39:02.701900Z","shell.execute_reply.started":"2022-01-26T10:38:43.300928Z","shell.execute_reply":"2022-01-26T10:39:02.701038Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#import warnings\n#warnings.simplefilter('error', UserWarning)\n\n#from IPython.core.interactiveshell import InteractiveShell\n#InteractiveShell.ast_node_interactivity = \"all\"\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom skimage import io\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Subset\nimport torchvision.transforms as tfs\nimport torchvision.models\nfrom torchsummary import summary\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\nfrom IPython.display import clear_output\nfrom tqdm.notebook import tqdm\nimport pickle\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:39:27.355799Z","iopub.execute_input":"2022-01-26T10:39:27.356074Z","iopub.status.idle":"2022-01-26T10:39:27.362144Z","shell.execute_reply.started":"2022-01-26T10:39:27.356046Z","shell.execute_reply":"2022-01-26T10:39:27.361482Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncontent_dir = '/kaggle/working/PH2Dataset'\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:39:31.546898Z","iopub.execute_input":"2022-01-26T10:39:31.547456Z","iopub.status.idle":"2022-01-26T10:39:31.601851Z","shell.execute_reply.started":"2022-01-26T10:39:31.547396Z","shell.execute_reply":"2022-01-26T10:39:31.600593Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data","metadata":{}},{"cell_type":"code","source":"if not os.path.exists(content_dir):\n    print('Download dataset...')\n    # !wget --quiet https://www.dropbox.com/s/k88qukc20ljnbuo/PH2Dataset.rar\n    !gdown https://drive.google.com/uc?id=12eqGNI4twFQKiiGVoWKQiblVIsdLK1vw -O PH2Dataset.zip\n    # print('Install unrar...', end='')\n    # !apt-get -qq install unrar > /dev/null 2>&1\n    # print('done.')\n    print('Extract archive files...', end='')\n    #!unrar x -idq PH2Dataset.rar\n    !unzip -q PH2Dataset.zip\n    print('done.')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:39:39.212045Z","iopub.execute_input":"2022-01-26T10:39:39.212304Z","iopub.status.idle":"2022-01-26T10:39:46.422685Z","shell.execute_reply.started":"2022-01-26T10:39:39.212276Z","shell.execute_reply":"2022-01-26T10:39:46.421780Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class CustomDataSet(Dataset):\n    def __init__(self, main_dir, transform):\n        self.transform = transform\n        self.samples = []\n        self.labels = []\n        for root, dirs, files in os.walk(main_dir):\n            if root.endswith('_Dermoscopic_Image'):\n                self.samples.append(os.path.join(root, files[0]))\n            if root.endswith('_lesion'):\n                self.labels.append(os.path.join(root, files[0]))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        # image = Image.open(self.samples[idx])\n        # label = Image.open(self.labels[idx])\n        image = cv2.imread(self.samples[idx])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = cv2.imread(self.labels[idx], cv2.IMREAD_GRAYSCALE)\n        transformed = self.transform(image=image, mask=label)\n        tensor_image = transformed['image'].transpose(2, 0, 1)\n        label_image = transformed['mask'][np.newaxis, :]\n        tensor_image = torch.FloatTensor(tensor_image) / 255\n        label_image = torch.FloatTensor(label_image) / 255\n        #print(tensor_image.shape, label_image.shape)\n        #print(tensor_image.min(), tensor_image.max(), label_image.min(), label_image.max())\n        return tensor_image, label_image\n    \n#     def __getitem__(self, idx):\n#         image = Image.open(self.samples[idx])\n#         tensor_image = self.transform(image)\n#         label = Image.open(self.labels[idx])\n#         label_image = self.transform(label)\n#         print(tensor_image.min(), tensor_image.max(), label_image.min(), label_image.max())\n#         return tensor_image, label_image","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:40:11.069692Z","iopub.execute_input":"2022-01-26T10:40:11.069977Z","iopub.status.idle":"2022-01-26T10:40:11.082435Z","shell.execute_reply.started":"2022-01-26T10:40:11.069944Z","shell.execute_reply":"2022-01-26T10:40:11.079491Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose([\n    A.Resize(256, 256),\n#     A.HorizontalFlip(),\n#     A.VerticalFlip(),\n#     A.augmentations.geometric.Affine(\n#         scale={'x':(1.0, 1.2), 'y':(1.0, 1.2)},\n# #        cval=[55, 51, 49],\n# #        mode=cv2.BORDER_CONSTANT\n#     )\n    #A.ToFloat(),\n    #A.pytorch.ToTensorV2(),\n    #A.Normalize(mean=0, std=1),\n    #tfs.RandomAffine(10,translate=(0.1, 0.1), scale=(0.9, 1.1)),\n])\n\n# transform = tfs.Compose([\n#     tfs.Resize((256, 256)),\n#     tfs.ToTensor(),\n# ])\n\ndermoscopic_dataset = CustomDataSet(os.path.join(content_dir, 'PH2 Dataset images'), transform=transform)\n\nidx = np.random.choice(len(dermoscopic_dataset), len(dermoscopic_dataset), False)\n#train_idx, valid_idx, test_idx = np.split(idx, [100, 150])\ntrain_idx, test_idx = np.split(idx, [150])\n\ndataset_train = Subset(dermoscopic_dataset, train_idx)\n#dataset_valid = Subset(dermoscopic_dataset, valid_idx)\ndataset_test  = Subset(dermoscopic_dataset, test_idx)\n\ndataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n#dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, shuffle=True)\ndataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:40:27.022585Z","iopub.execute_input":"2022-01-26T10:40:27.023329Z","iopub.status.idle":"2022-01-26T10:40:27.055290Z","shell.execute_reply.started":"2022-01-26T10:40:27.023292Z","shell.execute_reply":"2022-01-26T10:40:27.054540Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"def show_dermoscopic_imgs(images, labels, threshold=None):\n    images = images.numpy().transpose(0, 2, 3, 1)\n    labels = labels.numpy().transpose(0, 2, 3, 1)\n    if threshold is not None:\n        labels = np.where(labels > threshold, 1, 0)\n    plt.figure(figsize=(18, 6))\n    for i in range(4):\n        plt.subplot(2, 6, i+1)\n        plt.imshow(images[i])\n        plt.axis(\"off\")\n\n        plt.subplot(2, 6, i+7)\n        plt.imshow(labels[i], cmap='gray')\n        plt.axis(\"off\")\n    # plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:40:31.819245Z","iopub.execute_input":"2022-01-26T10:40:31.819513Z","iopub.status.idle":"2022-01-26T10:40:31.827199Z","shell.execute_reply.started":"2022-01-26T10:40:31.819484Z","shell.execute_reply":"2022-01-26T10:40:31.826523Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"images, labels = next(iter(dataloader_train))\nshow_dermoscopic_imgs(images, labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:40:35.324012Z","iopub.execute_input":"2022-01-26T10:40:35.324544Z","iopub.status.idle":"2022-01-26T10:40:36.032808Z","shell.execute_reply.started":"2022-01-26T10:40:35.324496Z","shell.execute_reply":"2022-01-26T10:40:36.032114Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def show_loss(history):\n    plt.figure(figsize=(12, 8))\n    plt.plot(history)\n    plt.title('Loss')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:40:40.875074Z","iopub.execute_input":"2022-01-26T10:40:40.875345Z","iopub.status.idle":"2022-01-26T10:40:40.880230Z","shell.execute_reply.started":"2022-01-26T10:40:40.875317Z","shell.execute_reply":"2022-01-26T10:40:40.879251Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Metrics\n\nGood summary: [A survey of loss functions for semantic segmentation](https://arxiv.org/pdf/2006.14822.pdf)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T13:13:39.409414Z","iopub.execute_input":"2021-11-18T13:13:39.409711Z","iopub.status.idle":"2021-11-18T13:13:39.413556Z","shell.execute_reply.started":"2021-11-18T13:13:39.409677Z","shell.execute_reply":"2021-11-18T13:13:39.412683Z"}}},{"cell_type":"markdown","source":"## IoU scoring metric\n\n$$I o U=\\frac{\\text {target } \\cap \\text { prediction }}{\\text {target } \\cup{prediction }}$$","metadata":{}},{"cell_type":"code","source":"SMOOTH = 1e-6\n# https://www.kaggle.com/iezepov/fast-iou-scoring-metric-in-pytorch-and-numpy\ndef iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n    outputs = outputs.byte()\n    labels = labels.byte()\n    #print(outputs)\n    # You can comment out this line if you are passing tensors of equal shape\n    # But if you are passing output from UNet or something it will most probably\n    # be with the BATCH x 1 x H x W shape\n    #outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n    # thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n    # return thresholded  # Or thresholded.mean() if you are interested in average across the batch\n    return iou","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:40:46.691682Z","iopub.execute_input":"2022-01-26T10:40:46.692365Z","iopub.status.idle":"2022-01-26T10:40:46.699042Z","shell.execute_reply.started":"2022-01-26T10:40:46.692328Z","shell.execute_reply":"2022-01-26T10:40:46.698316Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## BCE Loss\n\n$$\\mathcal L_{BCE}(y, \\hat y) = -\\sum_i \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right]$$","metadata":{"execution":{"iopub.status.busy":"2021-11-18T13:27:55.204072Z","iopub.execute_input":"2021-11-18T13:27:55.204598Z","iopub.status.idle":"2021-11-18T13:27:55.207505Z","shell.execute_reply.started":"2021-11-18T13:27:55.204565Z","shell.execute_reply":"2021-11-18T13:27:55.206925Z"}}},{"cell_type":"code","source":"class BCELoss_classic(nn.Module):\n    def __init__(self, reduction='mean'):\n        super().__init__()\n        if reduction not in ('mean', 'sum'):\n            raise ValueError('\"{}\" is not a valid mode for reduction. Only \"mean\"'\n                             'and \"sum\" are allowed.'.format(rediction))\n        self.reduction = reduction\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        # outputs = torch.clamp(outputs, 0, 1)\n        outputs = torch.sigmoid(outputs)\n        bce = labels * torch.log(outputs + SMOOTH) + (1 - labels) * torch.log(1 - outputs + SMOOTH)\n        if self.reduction == 'mean':\n            return -torch.mean(bce)\n        elif self.reduction == 'sum':\n            return -torch.sum(bce)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:40:50.211513Z","iopub.execute_input":"2022-01-26T10:40:50.211840Z","iopub.status.idle":"2022-01-26T10:40:50.221348Z","shell.execute_reply.started":"2022-01-26T10:40:50.211806Z","shell.execute_reply":"2022-01-26T10:40:50.220343Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"$$\\mathcal L_{BCE}(y, \\hat y) = \\hat y - y\\hat y + \\log\\left(1+\\exp(-\\hat y)\\right)$$","metadata":{}},{"cell_type":"code","source":"class BCELoss_with_logits(nn.Module):\n    def __init__(self, reduction='mean', truncate=False):\n        super().__init__()\n        if reduction not in ('mean', 'sum'):\n            raise ValueError('\"{}\" is not a valid mode for reduction. Only \"mean\"'\n                             'and \"sum\" are allowed.'.format(rediction))\n        self.reduction = reduction\n        self.truncate = truncate\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        # classical without sigmoid\n        # but you need to cut off large negative logits, otherwise it will be -inf -> nan \n        if self.truncate:\n            outputs = torch.sigmoid(outputs)\n        outputs = outputs.float()\n        labels = labels.float()\n        # print(torch.min(outputs))\n        bce = outputs - labels * outputs + torch.log(1 + torch.exp(-outputs))\n        if self.reduction == 'mean':\n            return torch.mean(bce)\n        elif self.reduction == 'sum':\n            return torch.sum(bce)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:40:53.651235Z","iopub.execute_input":"2022-01-26T10:40:53.651503Z","iopub.status.idle":"2022-01-26T10:40:53.658740Z","shell.execute_reply.started":"2022-01-26T10:40:53.651474Z","shell.execute_reply":"2022-01-26T10:40:53.658069Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# torch.mean(torch.log(1 + torch.exp(torch.tensor(255))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = torch.Tensor([\n    [-0.4717,  0.8484,  0.7424],\n    [ 0.0880,  0.1379,  0.8387],\n    [ 0.3874, -1.8205,  1.5422]\n])\ntarget = torch.Tensor([\n    [0, 1, 0],\n    [1, 0, 1],\n    [0, 1, 0]\n])\nsigm = nn.Sigmoid()\n\nprint(\n    output,\n    target,\n    nn.BCELoss(reduction='mean')(sigm(output), target),\n    BCELoss_classic(reduction='mean')(output, target),\n    BCELoss_with_logits(reduction='mean')(output, target),\n    sep='\\n'\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:40:58.219378Z","iopub.execute_input":"2022-01-26T10:40:58.219913Z","iopub.status.idle":"2022-01-26T10:40:58.300784Z","shell.execute_reply.started":"2022-01-26T10:40:58.219878Z","shell.execute_reply":"2022-01-26T10:40:58.300086Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Dice Loss\n\n$$D(X,Y)=\\frac{2|X\\cap Y|}{|X|+|Y|}$$\n\n$$\\mathcal L_D(X,Y) = 1-\\frac{1}{256 \\times 256} \\times \\sum_i\\frac{2X_iY_i}{X_i+Y_i}.$$","metadata":{}},{"cell_type":"code","source":"class DiceLoss(nn.Module):\n    def __init__(self, reduction='mean'):\n        super().__init__()\n\n#     # not work, why?\n#     def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n#         coef = 1 / (outputs.shape[0] * outputs.shape[2] * outputs.shape[3])\n#         outputs = torch.sigmoid(outputs)\n#         num = 2 * outputs * labels\n#         den = outputs + labels\n#         res = 1 - coef * ((num + 1)/(den + 1)).sum()\n#         return res\n\n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        outputs = torch.sigmoid(outputs)\n        num = 2 * (outputs * labels).sum()\n        den = (outputs + labels).sum()\n        res = 1 - (num + SMOOTH) / (den + SMOOTH)\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:02.011019Z","iopub.execute_input":"2022-01-26T10:41:02.011294Z","iopub.status.idle":"2022-01-26T10:41:02.017179Z","shell.execute_reply.started":"2022-01-26T10:41:02.011262Z","shell.execute_reply":"2022-01-26T10:41:02.016400Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Focal Loss\n\n$$FL(p_t) = -\\alpha_t(1-p_t)^\\gamma log(p_t)$$\n$$CE(p,y) = CE(p_t) = -log(p_t)$$\n$$p_t = e^{-CE(p_t)}$$\n$$FL(p_t) = \\alpha_t(1-e^{-CE(p_t)})^\\gamma CE(p_t)$$","metadata":{"execution":{"iopub.status.busy":"2021-11-21T09:15:44.629785Z","iopub.execute_input":"2021-11-21T09:15:44.630127Z","iopub.status.idle":"2021-11-21T09:15:44.635131Z","shell.execute_reply.started":"2021-11-21T09:15:44.630085Z","shell.execute_reply":"2021-11-21T09:15:44.634061Z"}}},{"cell_type":"code","source":"# https://arxiv.org/pdf/1708.02002.pdf\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha: int = 1, gamma: int = 2):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        bce_logit = nn.BCEWithLogitsLoss()\n        ce = bce_logit(outputs, labels)\n        pt = torch.exp(-ce)\n        fl = self.alpha * torch.pow((1 - pt), self.gamma) * ce\n        return fl","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:04.932776Z","iopub.execute_input":"2022-01-26T10:41:04.933284Z","iopub.status.idle":"2022-01-26T10:41:04.939934Z","shell.execute_reply.started":"2022-01-26T10:41:04.933248Z","shell.execute_reply":"2022-01-26T10:41:04.939221Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Tversky Loss\n\n[Tversky loss function for image segmentation using 3D fully convolutional deep networks](https://arxiv.org/abs/1706.05721)\n\n$$TI(p,\\hat p) = \\frac{p\\hat p}{p\\hat p + \\beta(1 − p)\\hat p + (1 − \\beta)p(1 − \\hat p)}$$\n$$TL(p,\\hat p) = 1 - \\frac{1 + p\\hat p}{1+ p\\hat p + \\beta(1 − p)\\hat p + (1 − \\beta)p(1 − \\hat p)}$$","metadata":{}},{"cell_type":"code","source":"class TverskyLoss(nn.Module):\n    def __init__(self, alpha:int = 0.5, beta:int = 0.5):\n        super().__init__()\n        self.alpha = alpha\n        self.beta = beta\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        outputs = torch.sigmoid(outputs)\n        pp = (labels * outputs).sum()\n        den1 = self.alpha * ((1 - labels) * outputs).sum()\n        den2 = self.beta * (labels * (1 - outputs)).sum()\n        tl = 1 - (1 + pp) / (1 + pp + den1 + den2)\n        return tl       ","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:08.130818Z","iopub.execute_input":"2022-01-26T10:41:08.131311Z","iopub.status.idle":"2022-01-26T10:41:08.137720Z","shell.execute_reply.started":"2022-01-26T10:41:08.131274Z","shell.execute_reply":"2022-01-26T10:41:08.136994Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Focal Tversky Loss","metadata":{}},{"cell_type":"code","source":"class FocalTverskyLoss(nn.Module):\n    def __init__(self, alpha:int = 0.5, beta:int = 0.5, gamma:int = 2):\n        super().__init__()\n        self.gamma = gamma\n        self.tl = TverskyLoss(alpha, beta)\n        \n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        tl = self.tl(outputs, labels)\n        return torch.pow(tl, self.gamma)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:10.498981Z","iopub.execute_input":"2022-01-26T10:41:10.499572Z","iopub.status.idle":"2022-01-26T10:41:10.507391Z","shell.execute_reply.started":"2022-01-26T10:41:10.499531Z","shell.execute_reply":"2022-01-26T10:41:10.506741Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Lovasz Loss","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/67791\nclass LovaszLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n        #outputs = torch.sigmoid(outputs)\n        outputs = outputs.flatten()\n        labels = labels.flatten()\n        signs = 2 * labels.float() - 1\n        errors = (1 - outputs * signs)\n        errors_sorted, indices = torch.sort(errors, dim=0, descending=True)\n        gt_sorted = labels[indices.data]\n\n        # gradient\n        gts = gt_sorted.sum()\n        intersection = gts - gt_sorted.float().cumsum(0)\n        union = gts + (1 - gt_sorted).float().cumsum(0)\n        grad = 1. - intersection / union\n\n        p = len(gt_sorted)\n        grad[1:p] = grad[1:p] - grad[0:-1]\n       \n        loss = torch.dot(torch.relu(errors_sorted), grad)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:12.978843Z","iopub.execute_input":"2022-01-26T10:41:12.979355Z","iopub.status.idle":"2022-01-26T10:41:12.989171Z","shell.execute_reply.started":"2022-01-26T10:41:12.979318Z","shell.execute_reply":"2022-01-26T10:41:12.988378Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Train/valid functions","metadata":{"execution":{"iopub.status.busy":"2021-11-21T13:33:36.596973Z","iopub.execute_input":"2021-11-21T13:33:36.598099Z","iopub.status.idle":"2021-11-21T13:33:36.625852Z","shell.execute_reply.started":"2021-11-21T13:33:36.597927Z","shell.execute_reply":"2021-11-21T13:33:36.624662Z"}}},{"cell_type":"code","source":"def score_model(model, metric, data, threshold=0):\n    model.to(device).eval() # testing mode\n    scores = 0\n    threshold = torch.tensor(threshold).to(device)\n    for X_batch, Y_label in data:\n        X_batch = X_batch.to(device)\n        with torch.no_grad():\n            Y_pred = model(X_batch)\n        scores += metric((Y_pred > threshold), Y_label.to(device)).mean().item()\n    return scores/len(data)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:16.164642Z","iopub.execute_input":"2022-01-26T10:41:16.165272Z","iopub.status.idle":"2022-01-26T10:41:16.171780Z","shell.execute_reply.started":"2022-01-26T10:41:16.165237Z","shell.execute_reply":"2022-01-26T10:41:16.170683Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_model(\n    model: torch.nn.Module,\n    criterion: torch.nn.Module,\n    optimizer: torch.nn.Module,\n    dataloader_train: torch.utils.data.DataLoader,\n    dataloader_test: torch.utils.data.DataLoader,\n    epochs: int = 20\n) -> (torch.nn.Module, dict):\n    r\"\"\"Training the model. Returns list of train losses.\n    Args:\n        model (torch.nn.Module): Neural network\n        criterion (torch.nn.Module): Cost function\n        optimizer (torch.nn.Module): Optimization algorithm\n        dataloader_train: (torch.utils.data.DataLoader): Train data\n        dataloader_valid: (torch.utils.data.DataLoader): Valid data\n        epochs (int): Number of training iterations. Default: 20\n    \"\"\"\n#def train(model, optimizer, loss_fn, epochs, data_tr, data_val):\n    X_val, Y_val = next(iter(dataloader_test))\n    losses = []\n    metric = []\n  \n    for epoch in range(epochs):\n        avg_loss = 0\n        model.train()  # train mode\n        for X_batch, Y_batch in tqdm(dataloader_train, desc='Progress'):\n            # data to device\n            X_batch = X_batch.to(device)\n            Y_batch = Y_batch.to(device)\n            # set parameter gradients to zero\n            optimizer.zero_grad()\n            # forward\n            # print(Y_batch.shape)\n            Y_pred = model(X_batch)\n            loss = criterion(Y_pred, Y_batch)\n            print(loss)\n            loss.backward() # backward-pass\n            optimizer.step()  # update weights\n            # calculate loss to show the user\n            avg_loss += loss / len(dataloader_train)\n\n        losses.append(avg_loss.item())\n        metric.append(score_model(model, iou_pytorch, dataloader_test))\n        \n        # show intermediate results\n        model.eval()  # testing mode\n        # detach and put into cpu\n        Y_hat = model(X_val.to(device)).detach().cpu()\n        # Visualize tools\n        clear_output(wait=True)\n        show_dermoscopic_imgs(X_val, Y_hat, threshold=0.1)\n        plt.title('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n        plt.show()\n    return losses, metric","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:18.675246Z","iopub.execute_input":"2022-01-26T10:41:18.675532Z","iopub.status.idle":"2022-01-26T10:41:18.688107Z","shell.execute_reply.started":"2022-01-26T10:41:18.675501Z","shell.execute_reply":"2022-01-26T10:41:18.687334Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def predict(model, data):\n    model.to(device).eval()  # testing mode\n    with torch.no_grad():\n        Y_pred = [model(X_batch.to(device)) for X_batch, _ in data]\n    return Y_pred","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:21.962881Z","iopub.execute_input":"2022-01-26T10:41:21.963391Z","iopub.status.idle":"2022-01-26T10:41:21.970432Z","shell.execute_reply.started":"2022-01-26T10:41:21.963354Z","shell.execute_reply":"2022-01-26T10:41:21.969432Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# SegNet","metadata":{}},{"cell_type":"code","source":"# vgg16 = torchvision.models.vgg16_bn()\n# vgg16.features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SegNet(nn.Module):\n    def _enc_layer(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n    \n    def _dec_layer(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1)),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n  \n    def __init__(self):\n        super().__init__()\n\n        # encoder (downsampling)\n        # Each enc_conv/dec_conv block should look like this:\n        # nn.Sequential(\n        #     nn.Conv2d(...),\n        #     ... (2 or 3 conv layers with relu and batchnorm),\n        # )\n\n        self.enc_conv0 = nn.Sequential(self._enc_layer(3, 64), self._enc_layer(64, 64))\n        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) # 256 -> 128\n        self.enc_conv1 = nn.Sequential(self._enc_layer(64, 128), self._enc_layer(128, 128))\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) # 128 -> 64\n        self.enc_conv2 = nn.Sequential(self._enc_layer(128, 256), self._enc_layer(256, 256), self._enc_layer(256, 256))\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) # 64 -> 32\n        self.enc_conv3 = nn.Sequential(self._enc_layer(256, 512), self._enc_layer(512, 512), self._enc_layer(512, 512))\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True) # 32 -> 16\n        # bottleneck?\n        # self.bottleneck_conv = \n        # https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html        \n        self.enc_conv_bn = nn.Sequential(self._enc_layer(512, 512), self._enc_layer(512, 512), self._enc_layer(512, 512))\n        self.pool_bn = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, return_indices=True)\n        self.upsample_bn = nn.MaxUnpool2d(kernel_size=2, stride=2, padding=0)\n        self.dec_conv_bn = nn.Sequential(self._dec_layer(512, 512), self._dec_layer(512, 512), self._dec_layer(512, 512))\n        # decoder (upsampling)\n        self.upsample0 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 16 -> 32\n        self.dec_conv0 = nn.Sequential(self._dec_layer(512, 512), self._dec_layer(512, 512), self._dec_layer(512, 256))\n        self.upsample1 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 32 -> 64\n        self.dec_conv1 = nn.Sequential(self._dec_layer(256, 256), self._dec_layer(256, 256), self._dec_layer(256, 128))\n        self.upsample2 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 64 -> 128\n        self.dec_conv2 = nn.Sequential(self._dec_layer(128, 128), self._dec_layer(128, 64))\n        self.upsample3 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 128 -> 256\n        self.dec_conv3 = nn.Sequential(\n            self._dec_layer(64, 64),\n            nn.ConvTranspose2d(64, 1, kernel_size=(3, 3), padding=(1, 1)),\n            # nn.BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n            # nn.ReLU(inplace=True)\n       )\n\n    def forward(self, x):\n        # encoder\n        e0, idx0 = self.pool0(self.enc_conv0(x))\n        e1, idx1 = self.pool1(self.enc_conv1(e0))\n        e2, idx2 = self.pool2(self.enc_conv2(e1))\n        e3, idx3 = self.pool3(self.enc_conv3(e2))\n\n        # bottleneck\n        # b = self.bottleneck_conv(e3)\n        p, idx_bn = self.pool_bn(self.enc_conv_bn(e3))\n        b = self.dec_conv_bn(self.upsample_bn(p, idx_bn))\n        \n        # decoder\n        d0 = self.dec_conv0(self.upsample0(b, idx3))\n        d1 = self.dec_conv1(self.upsample1(d0, idx2))\n        d2 = self.dec_conv2(self.upsample2(d1, idx1))\n        d3 = self.dec_conv3(self.upsample3(d2, idx0)) # no activation\n        return d3","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:26.852158Z","iopub.execute_input":"2022-01-26T10:41:26.852432Z","iopub.status.idle":"2022-01-26T10:41:26.875490Z","shell.execute_reply.started":"2022-01-26T10:41:26.852389Z","shell.execute_reply":"2022-01-26T10:41:26.874817Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"segnet = SegNet().to(device)\n# segnet\nsummary(segnet, input_size=(3, 256, 256), batch_size=batch_size)\ndel segnet","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:41:30.746755Z","iopub.execute_input":"2022-01-26T10:41:30.747411Z","iopub.status.idle":"2022-01-26T10:41:38.832618Z","shell.execute_reply.started":"2022-01-26T10:41:30.747374Z","shell.execute_reply":"2022-01-26T10:41:38.831895Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"segnet = SegNet().to(device)\noptim = torch.optim.Adam(segnet.parameters(), lr=1e-4)\nloss_func = BCELoss_with_logits()\n#loss_func = FocalTverskyLoss(0.6, 0.4, 2)\nlosses, metric = train_model(segnet, loss_func, optim, dataloader_train, dataloader_test, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:42:41.797271Z","iopub.execute_input":"2022-01-26T10:42:41.797820Z","iopub.status.idle":"2022-01-26T10:44:41.707794Z","shell.execute_reply.started":"2022-01-26T10:42:41.797783Z","shell.execute_reply":"2022-01-26T10:44:41.707122Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#score_model(segnet, iou_pytorch, dataloader_valid)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:52:06.372135Z","iopub.execute_input":"2022-01-26T10:52:06.372385Z","iopub.status.idle":"2022-01-26T10:52:06.375914Z","shell.execute_reply.started":"2022-01-26T10:52:06.372357Z","shell.execute_reply":"2022-01-26T10:52:06.374896Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# UNet","metadata":{}},{"cell_type":"code","source":"class UNet(nn.Module):\n    \n    def _conv_conv(self,in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n    \n    def _enc_layer(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            self._conv_conv(in_channels, out_channels)\n        )\n    \n    def __init__(self):\n        super().__init__()\n        \n        # encoder (downsampling)\n        # Each enc_conv/dec_conv block should look like this:\n        # nn.Sequential(\n        #     nn.Conv2d(...),\n        #     ... (2 or 3 conv layers with relu and batchnorm),\n        # )\n        \n        self.enc_conv0 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        )\n        self.enc_lr0 = self._enc_layer(64, 128)\n        self.enc_lr1 = self._enc_layer(128, 256)\n        self.enc_lr2 = self._enc_layer(256, 512)\n        self.enc_lr3 = self._enc_layer(512, 512)\n        # decoder (upsampling)\n        self.upsample0 = nn.Upsample(scale_factor=2)#ConvTranspose2d(1024, 512, kernel_size=2, stride=2) # 16 -> 32\n        self.dec_conv0 = self._conv_conv(2 * 512, 256)\n        self.upsample1 = nn.Upsample(scale_factor=2)#nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) # 32 -> 64\n        self.dec_conv1 = self._conv_conv(2 * 256, 128)\n        self.upsample2 = nn.Upsample(scale_factor=2)#nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) # 64 -> 128\n        self.dec_conv2 = self._conv_conv(2 * 128, 64)\n        self.upsample3 = nn.Upsample(scale_factor=2)#nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)  # 128 -> 256\n        self.dec_conv3 = nn.Sequential(\n            self._conv_conv(2 * 64, 64),\n            nn.Conv2d(64, 1, kernel_size=1),\n        )\n\n    def forward(self, x):\n        # encoder\n        e0 = self.enc_conv0(x)\n        e1 = self.enc_lr0(e0)\n        e2 = self.enc_lr1(e1)\n        e3 = self.enc_lr2(e2)\n        # bottleneck\n        b = self.upsample0(self.enc_lr3(e3))\n\n        # decoder\n        d0 = self.upsample1(self.dec_conv0(torch.cat((b, e3), dim=1)))\n        d1 = self.upsample2(self.dec_conv1(torch.cat((d0, e2), dim=1)))\n        d2 = self.upsample3(self.dec_conv2(torch.cat((d1, e1), dim=1)))\n        d3 = self.dec_conv3(torch.cat((d2, e0), dim=1))  # no activation\n        return d3","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:46:01.327823Z","iopub.execute_input":"2022-01-26T10:46:01.328076Z","iopub.status.idle":"2022-01-26T10:46:01.344751Z","shell.execute_reply.started":"2022-01-26T10:46:01.328048Z","shell.execute_reply":"2022-01-26T10:46:01.343899Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"unet = UNet().to(device)\n# unet\nsummary(unet, input_size=(3, 256, 256), batch_size=batch_size)\ndel unet","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:46:19.999862Z","iopub.execute_input":"2022-01-26T10:46:20.000170Z","iopub.status.idle":"2022-01-26T10:46:20.242398Z","shell.execute_reply.started":"2022-01-26T10:46:20.000136Z","shell.execute_reply":"2022-01-26T10:46:20.241477Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"unet = UNet().to(device)\noptim = torch.optim.Adam(unet.parameters(), lr=1e-4)\nloss_func = LovaszLoss()\nlosses, metric = train_model(unet, loss_func, optim, dataloader_train, dataloader_test, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:49:08.156007Z","iopub.execute_input":"2022-01-26T10:49:08.156273Z","iopub.status.idle":"2022-01-26T10:50:49.415914Z","shell.execute_reply.started":"2022-01-26T10:49:08.156243Z","shell.execute_reply":"2022-01-26T10:50:49.415269Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#score_model(unet, iou_pytorch, dataloader_valid)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:52:12.369071Z","iopub.execute_input":"2022-01-26T10:52:12.369729Z","iopub.status.idle":"2022-01-26T10:52:12.375246Z","shell.execute_reply.started":"2022-01-26T10:52:12.369694Z","shell.execute_reply":"2022-01-26T10:52:12.374439Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"class UNet2(nn.Module):\n    \n    def _conv_conv(self,in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n    \n    def _enc_layer(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1),\n            self._conv_conv(in_channels, out_channels)\n        )\n    \n    def __init__(self):\n        super().__init__()\n        \n        # encoder (downsampling)\n        # Each enc_conv/dec_conv block should look like this:\n        # nn.Sequential(\n        #     nn.Conv2d(...),\n        #     ... (2 or 3 conv layers with relu and batchnorm),\n        # )\n        \n        self.enc_conv0 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        )\n        self.enc_lr0 = self._enc_layer(64, 128)\n        self.enc_lr1 = self._enc_layer(128, 256)\n        self.enc_lr2 = self._enc_layer(256, 512)\n        self.enc_lr3 = self._enc_layer(512, 1024)\n        # decoder (upsampling)\n        self.upsample0 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2) # 16 -> 32\n        self.dec_conv0 = self._conv_conv(2 * 512, 512)\n        self.upsample1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) # 32 -> 64\n        self.dec_conv1 = self._conv_conv(2 * 256, 256)\n        self.upsample2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) # 64 -> 128\n        self.dec_conv2 = self._conv_conv(2 * 128, 128)\n        self.upsample3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)  # 128 -> 256\n        self.dec_conv3 = nn.Sequential(\n            self._conv_conv(2 * 64, 64),\n            nn.Conv2d(64, 1, kernel_size=1),\n        )\n\n    def forward(self, x):\n        # encoder\n        e0 = self.enc_conv0(x)\n        e1 = self.enc_lr0(e0)\n        e2 = self.enc_lr1(e1)\n        e3 = self.enc_lr2(e2)\n        # bottleneck\n        b = self.upsample0(self.enc_lr3(e3))\n\n        # decoder\n        d0 = self.upsample1(self.dec_conv0(torch.cat((b, e3), dim=1)))\n        d1 = self.upsample2(self.dec_conv1(torch.cat((d0, e2), dim=1)))\n        d2 = self.upsample3(self.dec_conv2(torch.cat((d1, e1), dim=1)))\n        d3 = self.dec_conv3(torch.cat((d2, e0), dim=1))  # no activation\n        return d3","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-01-26T10:52:14.592808Z","iopub.execute_input":"2022-01-26T10:52:14.593094Z","iopub.status.idle":"2022-01-26T10:52:14.612687Z","shell.execute_reply.started":"2022-01-26T10:52:14.593055Z","shell.execute_reply":"2022-01-26T10:52:14.611835Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"unet2 = UNet2().to(device)\n# unet2\nsummary(unet2, input_size=(3, 256, 256), batch_size=batch_size)\ndel unet2","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:52:18.704609Z","iopub.execute_input":"2022-01-26T10:52:18.705294Z","iopub.status.idle":"2022-01-26T10:52:19.014874Z","shell.execute_reply.started":"2022-01-26T10:52:18.705259Z","shell.execute_reply":"2022-01-26T10:52:19.014180Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"unet2 = UNet2().to(device)\noptim = torch.optim.Adam(unet.parameters(), lr=1e-4)\nloss_func = LovaszLoss()\nlosses, metric = train_model(unet, loss_func, optim, dataloader_train, dataloader_test, epochs=20)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:53:24.498036Z","iopub.execute_input":"2022-01-26T10:53:24.498865Z","iopub.status.idle":"2022-01-26T10:55:05.510897Z","shell.execute_reply.started":"2022-01-26T10:53:24.498819Z","shell.execute_reply":"2022-01-26T10:55:05.510228Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"# Model validation","metadata":{}},{"cell_type":"code","source":"def validate_model(model_class, model_file, pickle_file, max_epochs=40):\n    loss = {\n        #'bce': BCELoss_with_logits(reduction='mean', truncate=True),\n        'bce': BCELoss_classic(reduction='mean'),\n        #'bce': nn.BCEWithLogitsLoss(reduction='mean'),\n        'dice': DiceLoss(),\n        'focal': FocalLoss(),\n        'tversky': TverskyLoss(alpha=0.7, beta = 0.3),\n        'focal_tversky': FocalTverskyLoss(alpha=0.6, beta = 0.4, gamma=2),\n        'lovasz': LovaszLoss(),\n    }\n    model_history = {}\n    for loss_name, loss_func in loss.items():\n        model_history[loss_name] = {}\n        model = model_class().to(device)\n        optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n        losses, metric = train_model(model, loss_func, optim, dataloader_train, dataloader_test, max_epochs)\n        model_history[loss_name]['losses'] = losses\n        model_history[loss_name]['metric'] = metric\n        torch.save(model, '{}_{}_{}epoch.model'.format(model_file, loss_name, max_epochs))\n    with open(pickle_file, 'wb') as handle:\n        pickle.dump(model_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    return model_history","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:57:14.140909Z","iopub.execute_input":"2022-01-26T10:57:14.141398Z","iopub.status.idle":"2022-01-26T10:57:14.151794Z","shell.execute_reply.started":"2022-01-26T10:57:14.141362Z","shell.execute_reply":"2022-01-26T10:57:14.149112Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"max_epochs = 100\nsegnet_history = validate_model(SegNet, 'segnet', 'segnet.pickle', max_epochs=max_epochs)\nunet_history = validate_model(UNet, 'unet', 'unet.pickle', max_epochs=max_epochs)\nunet2_history = validate_model(UNet2, 'unet2', 'unet2.pickle', max_epochs=max_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T10:57:20.708979Z","iopub.execute_input":"2022-01-26T10:57:20.709697Z","iopub.status.idle":"2022-01-26T14:04:38.694464Z","shell.execute_reply.started":"2022-01-26T10:57:20.709660Z","shell.execute_reply":"2022-01-26T14:04:38.693709Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# with open('../input/temporary/segnet.pickle', 'rb') as handle:\n#     segnet_history = pickle.load(handle)\n# with open('../input/temporary/unet.pickle', 'rb') as handle:\n#     unet_history = pickle.load(handle)\n# with open('../input/temporary/unet2.pickle', 'rb') as handle:\n#     unet2_history = pickle.load(handle)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set(context='paper')\n\nfor history in [segnet_history, unet_history, unet2_history]:\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    x = list(range(max_epochs))\n    for key, value in history.items():\n        sns.lineplot(x=x, y=value['losses'], ax=ax[0], label=key)\n        sns.lineplot(x=x, y=value['metric'], ax=ax[1], label=key)\n    ax[0].set_title('loss')\n    ax[1].set_title('metric')\n    ax[0].legend()\n    ax[1].legend()\n    fig.show()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-26T14:14:43.930187Z","iopub.execute_input":"2022-01-26T14:14:43.930464Z","iopub.status.idle":"2022-01-26T14:14:46.618866Z","shell.execute_reply.started":"2022-01-26T14:14:43.930427Z","shell.execute_reply":"2022-01-26T14:14:46.618179Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"for history in [segnet_history, unet_history, unet2_history]:\n    ax = sns.barplot(x=list(history.keys()), y=[max(m['metric']) for m in history.values()])\n    ax.bar_label(ax.containers[0])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T14:07:40.348941Z","iopub.execute_input":"2022-01-26T14:07:40.349196Z","iopub.status.idle":"2022-01-26T14:07:41.000934Z","shell.execute_reply.started":"2022-01-26T14:07:40.349165Z","shell.execute_reply":"2022-01-26T14:07:41.000272Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"# Resume","metadata":{}},{"cell_type":"markdown","source":"**SegNet**\n\n* Total params: 29,443,585\n* Params size (MB): 112.32\n   \n**Unet (MaxPool2d/Upsample)**\n\n* Total params: 13,387,393\n* Params size (MB): 51.07\n\n**UNet (Conv2d/ConvTranspose2d)**\n\n* Total params: 34,166,145\n* Params size (MB): 130.33","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}